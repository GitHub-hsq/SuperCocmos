/**
 * ChatGPT åº“å®ç°çš„èŠå¤©æ¥å£
 * ä½¿ç”¨ chatgpt åº“è¿›è¡Œ API è°ƒç”¨
 */

import type { ChatGPTAPIOptions, SendMessageOptions } from 'chatgpt'
import type { ChatContext } from '../types'
import { ChatGPTAPI } from 'chatgpt'
import * as dotenv from 'dotenv'
import fetch from 'node-fetch'
import { sendResponse } from '../utils'
import { isNotEmptyString } from '../utils/is'
import { setupProxy } from './utils'

dotenv.config()

const disableDebug: boolean = process.env.OPENAI_API_DISABLE_DEBUG === 'true'
const timeoutMs: number = !Number.isNaN(+process.env.TIMEOUT_MS) ? +process.env.TIMEOUT_MS : 100 * 1000

interface LibraryChatOptions {
  message: string
  historyMessages?: Array<{ role: string, content: string }>
  lastContext?: ChatContext | null
  systemMessage?: string
  temperature?: number
  top_p?: number
  model: string
  maxTokens?: number
  baseURL?: string
  apiKey?: string
  processCallback?: (response: any) => void
}

/**
 * ä½¿ç”¨ chatgpt åº“è¿›è¡ŒèŠå¤©
 */
export async function chatReplyProcessLibrary(options: LibraryChatOptions) {
  const {
    message,
    historyMessages,
    lastContext,
    systemMessage,
    temperature,
    top_p,
    model,
    maxTokens,
    baseURL,
    apiKey,
    processCallback,
  } = options

  try {
    const startTime = Date.now()

    // åˆ›å»º API å®ä¾‹
    if (!baseURL || !apiKey) {
      throw new Error('ç¼ºå°‘å¿…éœ€çš„å‚æ•°: baseURL æˆ– apiKey')
    }

    const apiBaseUrl = baseURL.endsWith('/v1')
      ? baseURL
      : `${baseURL}/v1`

    // ğŸ”¥ å¦‚æœæœ‰å†å²æ¶ˆæ¯ï¼Œä½¿ç”¨åŸç”Ÿ fetch è°ƒç”¨ï¼ˆä¸ chatNative ç›¸åŒçš„é€»è¾‘ï¼‰
    if (historyMessages && historyMessages.length > 0) {
      const fullMessages = [
        ...historyMessages,
        { role: 'user', content: message },
      ]

      const apiUrl = `${apiBaseUrl}/chat/completions`

      const requestBody = {
        model,
        messages: fullMessages,
        temperature: temperature || 0.7,
        top_p: top_p || 1,
        max_tokens: maxTokens || 4096,
        stream: true,
      }

      console.log('[ChatGPTåº“-æµå¼] å‘é€è¯·æ±‚:', {
        url: apiUrl,
        model,
        messagesCount: fullMessages.length,
      })

      const fetchResponse = await fetch(apiUrl, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${apiKey}`,
        },
        body: JSON.stringify(requestBody),
      })

      if (!fetchResponse.ok) {
        throw new Error(`API è°ƒç”¨å¤±è´¥: ${fetchResponse.statusText}`)
      }

      // ä½¿ç”¨ Node.js æµå¤„ç†
      const body = fetchResponse.body as any
      let buffer = ''
      const messageId = `msg_${Date.now()}`
      let accumulatedText = ''

      // ç›‘å¬æµæ•°æ®
      body.on('data', (chunk: Buffer) => {
        buffer += chunk.toString('utf-8')
        const lines = buffer.split('\n')
        buffer = lines.pop() || ''

        for (const line of lines) {
          if (!line.trim() || line === 'data: [DONE]')
            continue

          if (line.startsWith('data: ')) {
            try {
              const jsonStr = line.substring(6)
              const data = JSON.parse(jsonStr)
              const delta = data.choices?.[0]?.delta?.content || ''

              if (delta) {
                accumulatedText += delta

                if (processCallback) {
                  processCallback({
                    id: messageId,
                    text: accumulatedText,
                    role: 'assistant',
                    detail: data,
                  } as any)
                }
              }
            }
            catch {
              // å¿½ç•¥è§£æé”™è¯¯
            }
          }
        }
      })

      // ç­‰å¾…æµç»“æŸ
      await new Promise((resolve, reject) => {
        body.on('end', resolve)
        body.on('error', reject)
      })

      const responseTime = Date.now() - startTime

      console.log('ğŸ“Š [ChatGPTåº“-æµå¼] å“åº”ä¿¡æ¯:', {
        time: `${responseTime}ms`,
        id: messageId,
        model,
        textLength: accumulatedText.length,
      })

      return sendResponse({
        type: 'Success',
        data: {
          id: messageId,
          text: accumulatedText,
          role: 'assistant',
          detail: {
            model,
            usage: {
              total_tokens: 0,
              estimated: true,
            },
          },
        },
      })
    }

    // ğŸ”¥ å¦åˆ™ä½¿ç”¨ chatgpt åº“çš„æ ‡å‡†è°ƒç”¨
    const apiOptions: ChatGPTAPIOptions = {
      apiKey,
      completionParams: { model },
      debug: !disableDebug,
      apiBaseUrl,
      maxModelTokens: 128000,
      maxResponseTokens: maxTokens || 8192,
    }

    setupProxy(apiOptions as any)
    const apiInstance = new ChatGPTAPI({ ...apiOptions })

    console.log('[ChatGPTåº“] å‘é€è¯·æ±‚:', {
      model,
      hasContext: !!lastContext,
    })

    // æ„å»ºå‘é€é€‰é¡¹
    let sendOptions: SendMessageOptions = {
      timeoutMs,
    }

    if (isNotEmptyString(systemMessage))
      sendOptions.systemMessage = systemMessage

    sendOptions.completionParams = {
      model,
      temperature,
      top_p,
    }

    if (lastContext != null) {
      sendOptions.parentMessageId = lastContext.parentMessageId
    }

    // ğŸ”¥ æ‰‹åŠ¨ç´¯ç§¯æ–‡æœ¬ï¼ˆä¿®å¤æŸäº›æ¨¡å‹çš„ text å­—æ®µä¸ºç©ºé—®é¢˜ï¼‰
    let accumulatedText = ''
    let accumulatedThinkingText = ''

    let _progressCallbackCount = 0
    const _progressStartTime = Date.now()
    let _lastProgressTime = _progressStartTime

    const response = await apiInstance.sendMessage(message, {
      ...sendOptions,
      onProgress: (partialResponse) => {
        _progressCallbackCount++
        const currentTime = Date.now()
        const _timeSinceLastProgress = currentTime - _lastProgressTime
        _lastProgressTime = currentTime

        // ğŸ”¥ ä» delta æˆ– detail.choices[0].delta.content è·å–å¢é‡å†…å®¹
        const delta = (partialResponse as any).delta || ''
        const content = (partialResponse.detail?.choices?.[0] as any)?.delta?.content || ''
        const reasoningContent = (partialResponse.detail?.choices?.[0] as any)?.delta?.reasoning_content || ''

        // ğŸ”¥ ç´¯ç§¯å®é™…å†…å®¹
        const actualContent = content || delta
        if (actualContent) {
          accumulatedText += actualContent
        }

        // ğŸ”¥ å¤„ç†æ€è€ƒè¿‡ç¨‹ï¼šå¦‚æœæœ‰ reasoning_contentï¼Œä¹Ÿä¼ é€’ç»™å‰ç«¯
        if (reasoningContent && !actualContent) {
          // ğŸ”¥ ç´¯ç§¯æ€è€ƒè¿‡ç¨‹
          accumulatedThinkingText += reasoningContent

          // æ€è€ƒè¿‡ç¨‹ï¼šæ˜¾ç¤ºæ€è€ƒçŠ¶æ€ï¼Œä½†ä¸ç´¯ç§¯åˆ°æœ€ç»ˆæ–‡æœ¬
          const thinkingText = `ğŸ’­ æ€è€ƒä¸­...\n${accumulatedThinkingText}`

          // åˆ›å»ºåŒ…å«æ€è€ƒè¿‡ç¨‹çš„å“åº”å¯¹è±¡
          const thinkingResponse = {
            ...partialResponse,
            text: thinkingText,
            isThinking: true, // æ ‡è®°è¿™æ˜¯æ€è€ƒè¿‡ç¨‹
          }

          processCallback?.(thinkingResponse)
          return
        }

        // å¦‚æœæ—¢æ²¡æœ‰å®é™…å†…å®¹ä¹Ÿæ²¡æœ‰æ€è€ƒå†…å®¹ï¼Œè·³è¿‡
        if (!actualContent && !reasoningContent) {
          return
        }

        // ğŸ”¥ ç¡®ä¿ text å­—æ®µæœ‰å€¼ï¼ˆä¿®å¤å‰ç«¯æ‰“å­—æœºæ•ˆæœï¼‰
        if (!partialResponse.text && accumulatedText) {
          partialResponse.text = accumulatedText
        }

        processCallback?.(partialResponse)
      },
    })

    const responseTime = Date.now() - startTime

    console.log('ğŸ“Š [ChatGPTåº“] å“åº”ä¿¡æ¯:', {
      time: `${responseTime}ms`,
      id: response.id,
      model: response.detail?.model || 'æœªçŸ¥',
      tokens: response.detail?.usage || 'æœªçŸ¥',
    })

    return sendResponse({ type: 'Success', data: response })
  }
  catch (error: any) {
    console.error('âŒ [ChatGPTåº“] å¤±è´¥:', error)
    return sendResponse({ type: 'Fail', message: error.message || 'è¯·æ±‚å¤±è´¥' })
  }
}
